# Build Journal - January 9, 2026

In this build journal, document all steps done with reasons why those steps were taken. Ensure that everything document has the date and time.

---

## Phase 1: Pose Detection Foundation - Initial Implementation

**Date:** January 9, 2026  
**Time:** ~20:00 PST

### Step 1: Create Pose Type Definitions
**Time:** ~19:50 PST

**Action:** Created comprehensive TypeScript type definitions for pose detection.

**Files Created:**
- `src/types/pose.ts` - Type definitions for pose detection

**Contents:**
- `KeypointIndex` enum - 17 keypoint indices (nose, eyes, ears, shoulders, elbows, wrists, hips, knees, ankles)
- `Keypoint` interface - Single keypoint with x, y, score
- `Pose` interface - Full pose detection result with keypoints array and overall score
- `SkeletonConnection` interface - Connection between two keypoints
- `SKELETON_CONNECTIONS` constant - Predefined skeleton connections for drawing

**Reason:** Strong typing is essential for TypeScript projects. These types will be used throughout the pose detection pipeline and ensure type safety when working with MoveNet output.

**Key Design Decisions:**
- Used enum for keypoint indices for better code readability
- Separated keypoint data structure from skeleton connections
- Included confidence scores in keypoint interface for filtering low-confidence detections

---

### Step 2: Implement Pose Detection Service
**Time:** ~19:52 PST

**Action:** Created the core pose detection service using TensorFlow.js and MoveNet Lightning.

**Files Created:**
- `src/services/poseDetection.ts` - Pose detection service

**Implementation Details:**
- Singleton pattern for service instance
- Async initialization method that loads MoveNet Lightning model from TensorFlow Hub
- Model URL: `https://tfhub.dev/google/tfjs-model/movenet/singlepose/lightning/4`
- Input size: 256x256 pixels (MoveNet Lightning requirement)
- Minimum keypoint confidence threshold: 0.3
- Proper tensor cleanup to prevent memory leaks

**Key Features:**
- `initialize()` - Loads TensorFlow.js and MoveNet model
- `isReady()` - Checks if service is initialized
- `detectPose(imageTensor)` - Processes image tensor and returns pose
- `dispose()` - Cleans up model resources

**Reason:** Centralized service for pose detection allows for easy testing, maintenance, and potential future optimizations. Singleton pattern ensures only one model instance is loaded.

**Technical Notes:**
- MoveNet Lightning chosen for speed (30+ FPS target)
- Model loads from TensorFlow Hub (no local bundling needed)
- Tensor cleanup is critical to prevent memory leaks in React Native
- Keypoints are filtered by confidence score before returning

**Challenges:**
- MoveNet outputs keypoints in format [y, x, score] - need to parse correctly
- Need to handle model loading errors gracefully
- Tensor disposal must be done carefully to avoid memory issues

---

### Step 3: Install React Native SVG
**Time:** ~19:54 PST

**Action:** Installed react-native-svg package for drawing keypoints and skeleton.

**Command:**
```bash
npm install react-native-svg --legacy-peer-deps
```

**Package Installed:**
- `react-native-svg@^15.15.1`

**Reason:** React Native SVG is the standard library for drawing vector graphics in React Native. Needed for drawing keypoints (circles) and skeleton connections (lines) on the camera overlay.

---

### Step 4: Create PoseOverlay Component
**Time:** ~19:55 PST

**Action:** Created component to visualize pose keypoints and skeleton on camera feed.

**Files Created:**
- `src/components/PoseOverlay.tsx` - Pose visualization overlay

**Implementation Details:**
- Uses React Native SVG for rendering
- Draws 17 keypoints as green circles
- Draws skeleton connections as green lines
- Scales coordinates from model input size (256x256) to screen coordinates
- Only renders keypoints with confidence > 0
- Opacity based on keypoint confidence scores

**Key Features:**
- Absolute positioning overlay (doesn't interfere with touch events)
- Dynamic scaling based on camera dimensions
- Visual feedback with opacity based on confidence
- Green color scheme for visibility

**Reason:** Visual feedback is essential for users to see that pose detection is working. Overlay approach allows pose visualization without blocking camera view.

**Design Decisions:**
- Green color chosen for good visibility on most backgrounds
- Keypoint radius: 4 pixels (visible but not obtrusive)
- Skeleton line width: 2 pixels
- Opacity tied to confidence for visual feedback on detection quality

---

### Step 5: Create CameraScreen
**Time:** ~19:58 PST

**Action:** Created main camera screen with pose detection integration.

**Files Created:**
- `src/screens/CameraScreen.tsx` - Camera screen with pose detection

**Implementation Details:**
- Uses Expo Camera (`CameraView` component)
- Camera permissions handling with user-friendly UI
- TensorFlow.js initialization on mount
- MoveNet model loading with loading states
- FPS counter for performance monitoring
- Pose confidence score display
- Error handling with user-friendly messages

**Key Features:**
- Permission request flow
- Loading states during model initialization
- Error handling and display
- FPS counter (updates every second)
- Pose confidence indicator
- Frame processing setup (placeholder for now)

**Reason:** CameraScreen is the core user interface for pose detection. Needs to handle all edge cases (permissions, loading, errors) gracefully.

**Technical Notes:**
- Camera aspect ratio: 4:3 (standard)
- Target FPS: 30 frames per second
- Frame interval: ~33ms between frames
- Front-facing camera by default (better for workout form analysis)

**Current Limitation:**
- Frame processing is currently a placeholder
- Need to implement actual frame capture from camera feed
- Will require expo-gl texture or alternative frame capture method

---

### Step 6: Update Navigation
**Time:** ~20:00 PST

**Action:** Added CameraScreen to navigation and updated HomeScreen with navigation button.

**Files Modified:**
- `App.tsx` - Added CameraScreen to Stack Navigator
- `src/screens/HomeScreen.tsx` - Added "Start Camera" button with navigation

**Changes:**
- Added Camera route to Stack Navigator
- Created navigation button on HomeScreen
- Styled button with green theme matching app design

**Reason:** Users need a way to access the camera screen. HomeScreen serves as the entry point with clear call-to-action.

**UI Design:**
- Green button (#00FF00) matching pose overlay color
- Bold text for visibility
- Rounded corners for modern look
- Proper spacing and margins

---

## Current Status

### Completed Tasks:
- ✅ Created pose type definitions
- ✅ Implemented pose detection service
- ✅ Installed React Native SVG
- ✅ Created PoseOverlay component
- ✅ Created CameraScreen with basic structure
- ✅ Added navigation and UI elements

### Partially Completed:
- ⚠️ Frame processing implementation (placeholder - needs actual frame capture)

### Next Steps:
1. Test current implementation on device
2. Implement proper frame capture from camera feed
3. Wire frame capture to pose detection service
4. Test pose detection accuracy and performance
5. Optimize for target 25-30 FPS

### Known Issues:
- Frame processing not yet implemented - camera will display but pose detection won't run
- Need to research best method for frame capture (expo-gl texture vs alternatives)
- Model loading time may be slow on first launch (consider caching)

### Files Created/Modified:
**New Files:**
- `src/types/pose.ts`
- `src/services/poseDetection.ts`
- `src/components/PoseOverlay.tsx`
- `src/screens/CameraScreen.tsx`

**Modified Files:**
- `App.tsx` - Added Camera route
- `src/screens/HomeScreen.tsx` - Added navigation button
- `package.json` - Added react-native-svg dependency

---

## Testing Plan

**Before Testing:**
- Verify all files compile without errors
- Check that dependencies are installed
- Ensure camera permissions are configured in app.json

**Testing Steps:**
1. Start Expo development server
2. Open app on physical device (camera doesn't work in simulator)
3. Navigate to Camera screen from Home
4. Verify camera feed displays
5. Check that model loads (loading indicator should disappear)
6. Verify FPS counter appears (will show 0 until frame processing is implemented)
7. Test error handling (if model fails to load)

**Expected Behavior:**
- Camera feed should display smoothly
- Model should load within 5-10 seconds
- FPS counter should appear in top-left
- No crashes or errors

**Known Limitations:**
- Pose detection won't work yet (frame processing not implemented)
- FPS will show 0 until frame capture is working

---

## Fix: Missing Dependencies and Version Mismatches

**Date:** January 9, 2026  
**Time:** ~21:06 PST

### Issues Encountered
**Time:** 21:05 PST

**Problem 1:** Missing dependency error:
```
Unable to resolve "react-native-fs" from "node_modules/@tensorflow/tfjs-react-native/dist/bundle_resource_io.js"
```

**Problem 2:** Package version mismatches:
- `react-native-svg@15.15.1` - expected version: `15.12.1`
- `react-native-worklets@0.7.1` - expected version: `0.5.1`

**Root Cause:**
- TensorFlow.js React Native requires `react-native-fs` as a peer dependency for file system operations
- Package versions were installed with `latest` instead of Expo SDK 54 compatible versions

### Fixes Applied
**Time:** 21:05-21:06 PST

**Actions Taken:**
1. Installed missing dependency:
   - `react-native-fs@^2.20.0` - Required by @tensorflow/tfjs-react-native for bundle resource I/O

2. Fixed package version mismatches:
   - `react-native-svg`: `15.15.1` → `15.12.1` (Expo SDK 54 compatible)
   - `react-native-worklets`: `0.7.1` → `0.5.1` (Expo SDK 54 compatible)

**Installation Method:** Used `npm install` with `--legacy-peer-deps` flag due to TensorFlow.js React Native peer dependency conflicts.

**Files Modified:**
- `package.json` - Added react-native-fs, updated package versions

**Verification:**
- All packages successfully installed
- No linting errors
- Dependencies now match Expo SDK 54 requirements

**Result:**
✅ Missing `react-native-fs` dependency installed
✅ Package versions now match Expo SDK 54 requirements
✅ Bundling error should be resolved

**Note:** `react-native-fs` is not available via `expo install` (it's a community package), so it was installed directly via npm. This is expected and shouldn't cause issues.

**Next Steps:**
- Test app bundling again
- Verify no more dependency errors
- Continue with testing Phase 1 implementation

---

## Improvement: Better Model Loading Feedback and Timeout

**Date:** January 9, 2026  
**Time:** ~21:10 PST

### Issue Encountered
**Time:** 21:08 PST

**Problem:** User reported that model loading was taking a long time with no feedback on progress or expected duration.

**Root Cause:**
- MoveNet Lightning model (~7MB) is downloaded from TensorFlow Hub on first load
- No progress indication or timeout handling
- Users don't know if it's working or stuck
- First load can take 30-60+ seconds depending on network speed

### Improvements Applied
**Time:** 21:09-21:10 PST

**Actions Taken:**
1. Added progress callback to `poseDetectionService.initialize()`:
   - Shows "Initializing TensorFlow.js..." first
   - Then "Downloading MoveNet model (this may take 30-60 seconds on first load)..."
   - Finally "Model loaded successfully!"

2. Added timeout handling:
   - 90-second timeout for model loading
   - Helpful error message if timeout occurs
   - Suggests checking internet connection

3. Enhanced loading UI:
   - Dynamic loading message that updates with progress
   - Added hint text explaining first load takes longer
   - Better error messages for network issues

4. Improved error messages:
   - Distinguishes between timeout, network, and other errors
   - Provides actionable guidance to users

**Files Modified:**
- `src/services/poseDetection.ts` - Added progress callback and timeout
- `src/screens/CameraScreen.tsx` - Enhanced loading UI with progress messages

**Expected Load Times:**
- **First load:** 30-60 seconds (downloads ~7MB from TensorFlow Hub)
- **Slow network:** 60-90+ seconds
- **Subsequent loads:** Still downloads each time (no caching yet)
- **Timeout:** 90 seconds (will show error if exceeded)

**Future Optimization:**
- Consider caching model locally after first download
- Use AsyncStorage or file system to store model
- Load from cache on subsequent app launches

**Result:**
✅ Users now see progress messages during model loading
✅ Timeout prevents indefinite waiting
✅ Better error messages for troubleshooting
✅ Users understand why first load takes longer

**Next Steps:**
- Test model loading with new feedback
- Consider implementing local model caching for faster subsequent loads
